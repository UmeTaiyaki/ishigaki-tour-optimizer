import os
import json
import sqlite3
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, r2_score
import joblib
from typing import Dict, List, Tuple
import requests

class IshigakiMLPredictor:
    """çŸ³å£å³¶å°‚ç”¨æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self):
        self.models = {
            'rf': None,  # Random Forest
            'gb': None,  # Gradient Boosting
            'nn': None   # Neural Network
        }
        
        # çŸ³å£å³¶ç‰¹æœ‰ã®é‡ã¿èª¿æ•´
        self.ensemble_weights = {'rf': 0.45, 'gb': 0.35, 'nn': 0.2}
        self.feature_names = []
        self.last_trained = None
        self.model_dir = 'models'
        
        # çŸ³å£å³¶ã®ç‰¹å¾´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.ishigaki_features = {
            'tourist_seasons': {
                'peak': [1, 2, 3, 7, 8, 12],      # è¦³å…‰ãƒ”ãƒ¼ã‚¯æœˆ
                'high': [4, 5, 11],                # è¦³å…‰ç¹å¿™æœˆ
                'normal': [6, 9, 10]               # é€šå¸¸æœˆ
            },
            'typhoon_months': [6, 7, 8, 9, 10, 11],
            'rain_months': [5, 6, 9, 10],
            'cruise_ship_days': [1, 15],  # æœˆ2å›ç¨‹åº¦ã®ã‚¯ãƒ«ãƒ¼ã‚ºèˆ¹å¯„æ¸¯
            'areas': {
                'city_center': {'traffic_multiplier': 1.4, 'tourist_density': 'high'},
                'kabira_bay': {'traffic_multiplier': 1.3, 'tourist_density': 'very_high'},
                'shiraho': {'traffic_multiplier': 0.9, 'tourist_density': 'medium'},
                'yonehara': {'traffic_multiplier': 0.8, 'tourist_density': 'medium'},
                'fusaki': {'traffic_multiplier': 1.1, 'tourist_density': 'high'},
                'airport': {'traffic_multiplier': 1.2, 'tourist_density': 'high'},
                'north_coast': {'traffic_multiplier': 0.7, 'tourist_density': 'low'}
            }
        }
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs(self.model_dir, exist_ok=True)
    
    def train_from_records(self) -> Dict:
        """çŸ³å£å³¶ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰çŸ³å£å³¶ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            conn = sqlite3.connect('tour_data.db')
            query = """
            SELECT * FROM pickup_records 
            WHERE delay_minutes IS NOT NULL
            AND created_at >= date('now', '-2 years')
            ORDER BY created_at DESC
            LIMIT 2000
            """
            df = pd.read_sql_query(query, conn)
            conn.close()
            
            if len(df) < 30:  # çŸ³å£å³¶ã¯å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å­¦ç¿’é–‹å§‹
                return {
                    'success': False,
                    'message': f'çŸ³å£å³¶å°‚ç”¨ãƒ¢ãƒ‡ãƒ«: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ {len(df)}ä»¶ï¼ˆæœ€ä½30ä»¶å¿…è¦ï¼‰'
                }
            
            # çŸ³å£å³¶ç‰¹æœ‰ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
            X, y = self._prepare_ishigaki_features(df)
            
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆçŸ³å£å³¶ã®å­£ç¯€æ€§ã‚’è€ƒæ…®ï¼‰
            X_train, X_test, y_train, y_test = self._seasonal_train_test_split(X, y, df)
            
            # å„ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ï¼ˆçŸ³å£å³¶æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            results = {}
            
            # Random Forestï¼ˆçŸ³å£å³¶ç‰¹åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            self.models['rf'] = RandomForestRegressor(
                n_estimators=150,        # å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å®‰å®š
                max_depth=8,             # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°é˜²æ­¢
                min_samples_split=5,     # çŸ³å£å³¶ã®ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã«åˆã‚ã›ã¦
                min_samples_leaf=3,
                max_features='sqrt',
                random_state=42
            )
            self.models['rf'].fit(X_train, y_train)
            rf_pred = self.models['rf'].predict(X_test)
            results['rf'] = {
                'mae': mean_absolute_error(y_test, rf_pred),
                'r2': r2_score(y_test, rf_pred)
            }
            
            # Gradient Boostingï¼ˆçŸ³å£å³¶è¦³å…‰ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰
            self.models['gb'] = GradientBoostingRegressor(
                n_estimators=120,
                learning_rate=0.08,      # ã‚†ã£ãã‚Šå­¦ç¿’ã§å®‰å®šæ€§é‡è¦–
                max_depth=4,
                min_samples_split=8,
                subsample=0.8,           # ãƒã‚®ãƒ³ã‚°åŠ¹æœ
                random_state=42
            )
            self.models['gb'].fit(X_train, y_train)
            gb_pred = self.models['gb'].predict(X_test)
            results['gb'] = {
                'mae': mean_absolute_error(y_test, gb_pred),
                'r2': r2_score(y_test, gb_pred)
            }
            
            # Neural Networkï¼ˆçŸ³å£å³¶ã®è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ï¼‰
            self.models['nn'] = MLPRegressor(
                hidden_layer_sizes=(40, 20),  # å³¶ã®è¦æ¨¡ã«åˆã‚ã›ã¦ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆ
                max_iter=800,
                learning_rate_init=0.01,
                alpha=0.1,                     # æ­£å‰‡åŒ–å¼·ã‚
                random_state=42,
                early_stopping=True,
                validation_fraction=0.2
            )
            self.models['nn'].fit(X_train, y_train)
            nn_pred = self.models['nn'].predict(X_test)
            results['nn'] = {
                'mae': mean_absolute_error(y_test, nn_pred),
                'r2': r2_score(y_test, nn_pred)
            }
            
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã®è©•ä¾¡
            ensemble_pred = (
                self.ensemble_weights['rf'] * rf_pred +
                self.ensemble_weights['gb'] * gb_pred +
                self.ensemble_weights['nn'] * nn_pred
            )
            results['ensemble'] = {
                'mae': mean_absolute_error(y_test, ensemble_pred),
                'r2': r2_score(y_test, ensemble_pred)
            }
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            self._save_models()
            
            # ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆçŸ³å£å³¶ç‰¹æœ‰è¦å› ã®åˆ†æï¼‰
            feature_importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.models['rf'].feature_importances_
            }).sort_values('importance', ascending=False)
            
            return {
                'success': True,
                'location': 'çŸ³å£å³¶å°‚ç”¨ãƒ¢ãƒ‡ãƒ«',
                'data_size': len(df),
                'results': results,
                'ishigaki_feature_importance': feature_importance.head(15).to_dict('records'),
                'model_notes': self._generate_model_notes(feature_importance)
            }
            
        except Exception as e:
            print(f"çŸ³å£å³¶ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'success': False,
                'message': f'çŸ³å£å³¶ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å¤±æ•—: {str(e)}'
            }
    
    def _prepare_ishigaki_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """çŸ³å£å³¶ç‰¹æœ‰ã®ç‰¹å¾´é‡ã‚’æº–å‚™"""
        features = pd.DataFrame()
        
        # åŸºæœ¬ç‰¹å¾´é‡
        features['distance_km'] = df['distance_km']
        
        # æ™‚é–“é–¢é€£ç‰¹å¾´é‡
        df['planned_datetime'] = pd.to_datetime(df['planned_time'])
        features['hour'] = df['planned_datetime'].dt.hour
        features['minute'] = df['planned_datetime'].dt.minute
        features['day_of_week'] = df['planned_datetime'].dt.dayofweek
        features['day_of_month'] = df['planned_datetime'].dt.day
        features['is_weekend'] = (features['day_of_week'] >= 5).astype(int)
        
        # çŸ³å£å³¶ç‰¹æœ‰ã®æ™‚é–“å¸¯ç‰¹å¾´é‡
        features['is_morning_rush'] = features['hour'].apply(
            lambda x: 1 if 7 <= x <= 9 else 0
        )
        features['is_tourist_peak'] = features['hour'].apply(
            lambda x: 1 if 10 <= x <= 14 else 0
        )
        features['is_evening_rush'] = features['hour'].apply(
            lambda x: 1 if 17 <= x <= 19 else 0
        )
        
        # å­£ç¯€ãƒ»è¦³å…‰ç‰¹å¾´é‡
        features['month'] = df['planned_datetime'].dt.month
        features['tourist_season'] = features['month'].apply(self._get_tourist_season)
        features['is_typhoon_season'] = features['month'].apply(
            lambda x: 1 if x in self.ishigaki_features['typhoon_months'] else 0
        )
        features['is_rain_season'] = features['month'].apply(
            lambda x: 1 if x in self.ishigaki_features['rain_months'] else 0
        )
        
        # ã‚¯ãƒ«ãƒ¼ã‚ºèˆ¹å¯„æ¸¯æ—¥ã®å½±éŸ¿
        features['is_cruise_day'] = features['day_of_month'].apply(
            lambda x: 1 if x in self.ishigaki_features['cruise_ship_days'] else 0
        )
        
        # å¤©å€™ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆçŸ³å£å³¶ç‰¹æœ‰ã®å¤©å€™ï¼‰
        weather_dummies = pd.get_dummies(df['weather'], prefix='weather')
        features = pd.concat([features, weather_dummies], axis=1)
        
        # æ½®ä½ç‰¹å¾´é‡ï¼ˆçŸ³å£å³¶ã®æµ·æ´‹ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£é‡è¦ï¼‰
        features['tide_level'] = df['tide_level']
        features['is_high_tide'] = (features['tide_level'] > 150).astype(int)
        features['is_very_high_tide'] = (features['tide_level'] > 180).astype(int)
        features['is_low_tide'] = (features['tide_level'] < 100).astype(int)
        
        # æ½®ä½ã¨æ™‚é–“ã®çµ„ã¿åˆã‚ã›ç‰¹å¾´é‡
        features['tide_hour_interaction'] = features['tide_level'] * features['hour']
        
        # ã‚¨ãƒªã‚¢ç‰¹å¾´é‡ï¼ˆãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—å ´æ‰€ã®ç‰¹æ€§ï¼‰
        if 'pickup_area' in df.columns:
            area_dummies = pd.get_dummies(df['pickup_area'], prefix='area')
            features = pd.concat([features, area_dummies], axis=1)
        
        # ç§»å‹•è·é›¢ã‚«ãƒ†ã‚´ãƒª
        features['distance_category'] = pd.cut(
            features['distance_km'], 
            bins=[0, 5, 10, 20, float('inf')], 
            labels=['short', 'medium', 'long', 'very_long']
        )
        distance_cat_dummies = pd.get_dummies(features['distance_category'], prefix='dist')
        features = pd.concat([features, distance_cat_dummies], axis=1)
        features.drop('distance_category', axis=1, inplace=True)
        
        # è¦³å…‰å®¢å¯†åº¦ï¼ˆä»®æƒ³ç‰¹å¾´é‡ï¼šå®Ÿéš›ã¯å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã¨é€£æºï¼‰
        features['tourist_density_score'] = (
            features['tourist_season'] * 
            features['is_weekend'] * 
            features['is_tourist_peak']
        ).apply(lambda x: min(x, 3))
        
        # äº¤é€šæ¸‹æ»äºˆæ¸¬ã‚¹ã‚³ã‚¢
        features['traffic_congestion_score'] = (
            features['is_morning_rush'] * 2 +
            features['is_evening_rush'] * 2 +
            features['is_tourist_peak'] * 1 +
            features['is_cruise_day'] * 3 +
            features['tourist_season']
        )
        
        # ç‰¹å¾´é‡åã‚’ä¿å­˜
        self.feature_names = features.columns.tolist()
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        y = df['delay_minutes']
        
        return features, y
    
    def _get_tourist_season(self, month: int) -> int:
        """æœˆã‹ã‚‰è¦³å…‰ã‚·ãƒ¼ã‚ºãƒ³ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—"""
        if month in self.ishigaki_features['tourist_seasons']['peak']:
            return 3  # ãƒ”ãƒ¼ã‚¯
        elif month in self.ishigaki_features['tourist_seasons']['high']:
            return 2  # ç¹å¿™
        else:
            return 1  # é€šå¸¸
    
    def _seasonal_train_test_split(self, X: pd.DataFrame, y: pd.Series, df: pd.DataFrame):
        """å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸãƒ‡ãƒ¼ã‚¿åˆ†å‰²"""
        # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«ï¼ˆå­£ç¯€å¤‰å‹•ã‚’ã‚ˆã‚Šæ­£ç¢ºã«è©•ä¾¡ï¼‰
        df_with_features = pd.concat([X, y], axis=1)
        df_with_features['date'] = pd.to_datetime(df['planned_time'])
        df_sorted = df_with_features.sort_values('date')
        
        # æœ€æ–°20%ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨
        test_size = int(len(df_sorted) * 0.2)
        
        train_data = df_sorted[:-test_size]
        test_data = df_sorted[-test_size:]
        
        X_train = train_data.drop(['delay_minutes', 'date'], axis=1)
        y_train = train_data['delay_minutes']
        X_test = test_data.drop(['delay_minutes', 'date'], axis=1)
        y_test = test_data['delay_minutes']
        
        return X_train, X_test, y_train, y_test
    
    def predict_tour_performance(self, date: str, activity_type: str,
                                guests: List[Dict], activity_location: Dict) -> Dict:
        """çŸ³å£å³¶ãƒ„ã‚¢ãƒ¼ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬"""
        predictions = {
            'confidence_score': 85,
            'expected_delays': [],
            'recommendations': [],
            'ishigaki_weather_alert': [],
            'tide_advisory': []
        }
        
        # ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
        if not any(model is not None for model in self.models.values()):
            predictions['recommendations'].append(
                "ğŸï¸ çŸ³å£å³¶å°‚ç”¨äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã§ã™ã€‚å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ä¸­ã§ã™ã€‚"
            )
            return predictions
        
        # çŸ³å£å³¶ã®ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        environmental_data = self._get_ishigaki_environmental_data(date)
        
        # å„ã‚²ã‚¹ãƒˆã®é…å»¶äºˆæ¸¬
        for guest in guests:
            delay_pred = self._predict_ishigaki_delay(
                guest=guest,
                date=date,
                activity_type=activity_type,
                environmental_data=environmental_data
            )
            
            predictions['expected_delays'].append({
                'guest_name': guest['name'],
                'predicted_delay': delay_pred['prediction'],
                'confidence_interval': delay_pred['confidence_interval'],
                'ishigaki_factors': delay_pred['ishigaki_factors']
            })
        
        # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆçŸ³å£å³¶ç‰¹æœ‰ï¼‰
        predictions['confidence_score'] = self._calculate_ishigaki_confidence(
            len(guests), environmental_data
        )
        
        # çŸ³å£å³¶ç‰¹æœ‰ã®æ¨å¥¨äº‹é …ç”Ÿæˆ
        predictions['recommendations'] = self._generate_ishigaki_recommendations(
            date, activity_type, predictions['expected_delays'], environmental_data
        )
        
        # å¤©å€™ãƒ»æ½®ä½ã‚¢ãƒ©ãƒ¼ãƒˆ
        predictions['ishigaki_weather_alert'] = self._generate_weather_alerts(environmental_data)
        predictions['tide_advisory'] = self._generate_tide_advisory(environmental_data)
        
        return predictions
    
    def _predict_ishigaki_delay(self, guest: Dict, date: str, activity_type: str,
                              environmental_data: Dict) -> Dict:
        """çŸ³å£å³¶ã®å€‹åˆ¥ã‚²ã‚¹ãƒˆé…å»¶äºˆæ¸¬"""
        
        # ç‰¹å¾´é‡ã®æº–å‚™
        features = self._prepare_guest_features(guest, date, activity_type, environmental_data)
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬
        predictions = {}
        for name, model in self.models.items():
            if model is not None:
                try:
                    predictions[name] = model.predict(features)[0]
                except Exception as e:
                    print(f"äºˆæ¸¬ã‚¨ãƒ©ãƒ¼ {name}: {e}")
                    predictions[name] = 0
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        if predictions:
            ensemble_pred = sum(
                self.ensemble_weights.get(name, 0) * pred 
                for name, pred in predictions.items()
            )
        else:
            ensemble_pred = 0
        
        # çŸ³å£å³¶ç‰¹æœ‰ã®èª¿æ•´
        ensemble_pred = self._apply_ishigaki_adjustments(
            ensemble_pred, guest, environmental_data
        )
        
        # ä¿¡é ¼åŒºé–“
        std_dev = np.std(list(predictions.values())) if predictions else 3
        
        return {
            'prediction': max(0, int(ensemble_pred)),
            'confidence_interval': (
                max(0, int(ensemble_pred - 1.96 * std_dev)),
                int(ensemble_pred + 1.96 * std_dev)
            ),
            'individual_predictions': predictions,
            'ishigaki_factors': self._identify_ishigaki_factors(guest, environmental_data)
        }
    
    def _prepare_guest_features(self, guest: Dict, date: str, activity_type: str,
                              environmental_data: Dict) -> pd.DataFrame:
        """ã‚²ã‚¹ãƒˆç”¨ç‰¹å¾´é‡æº–å‚™"""
        
        try:
            date_obj = datetime.strptime(date, '%Y-%m-%d')
            pickup_time = datetime.strptime(guest.get('preferred_pickup_start', '09:00'), '%H:%M')
        except:
            date_obj = datetime.now()
            pickup_time = datetime.now().replace(hour=9, minute=0)
        
        # è·é›¢è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        distance = 10.0  # å®Ÿéš›ã¯activity_locationã¨ã®è·é›¢ã‚’è¨ˆç®—
        
        features = pd.DataFrame({
            'distance_km': [distance],
            'hour': [pickup_time.hour],
            'minute': [pickup_time.minute],
            'day_of_week': [date_obj.weekday()],
            'day_of_month': [date_obj.day],
            'is_weekend': [1 if date_obj.weekday() >= 5 else 0],
            'is_morning_rush': [1 if 7 <= pickup_time.hour <= 9 else 0],
            'is_tourist_peak': [1 if 10 <= pickup_time.hour <= 14 else 0],
            'is_evening_rush': [1 if 17 <= pickup_time.hour <= 19 else 0],
            'month': [date_obj.month],
            'tourist_season': [self._get_tourist_season(date_obj.month)],
            'is_typhoon_season': [1 if date_obj.month in self.ishigaki_features['typhoon_months'] else 0],
            'is_rain_season': [1 if date_obj.month in self.ishigaki_features['rain_months'] else 0],
            'is_cruise_day': [1 if date_obj.day in self.ishigaki_features['cruise_ship_days'] else 0],
            'tide_level': [environmental_data.get('tide_level', 150)],
            'is_high_tide': [1 if environmental_data.get('tide_level', 150) > 150 else 0],
            'is_very_high_tide': [1 if environmental_data.get('tide_level', 150) > 180 else 0],
            'is_low_tide': [1 if environmental_data.get('tide_level', 150) < 100 else 0],
            'tide_hour_interaction': [environmental_data.get('tide_level', 150) * pickup_time.hour],
        })
        
        # å¤©å€™ãƒ€ãƒŸãƒ¼å¤‰æ•°
        weather = environmental_data.get('weather', 'sunny')
        for weather_type in ['sunny', 'cloudy', 'rainy', 'typhoon']:
            features[f'weather_{weather_type}'] = 1 if weather == weather_type else 0
        
        # è·é›¢ã‚«ãƒ†ã‚´ãƒªãƒ€ãƒŸãƒ¼å¤‰æ•°
        if distance <= 5:
            dist_category = 'short'
        elif distance <= 10:
            dist_category = 'medium'
        elif distance <= 20:
            dist_category = 'long'
        else:
            dist_category = 'very_long'
        
        for cat in ['short', 'medium', 'long', 'very_long']:
            features[f'dist_{cat}'] = 1 if dist_category == cat else 0
        
        # ãã®ä»–ã®ç‰¹å¾´é‡
        features['tourist_density_score'] = (
            features['tourist_season'].iloc[0] * 
            features['is_weekend'].iloc[0] * 
            features['is_tourist_peak'].iloc[0]
        )
        
        features['traffic_congestion_score'] = (
            features['is_morning_rush'].iloc[0] * 2 +
            features['is_evening_rush'].iloc[0] * 2 +
            features['is_tourist_peak'].iloc[0] * 1 +
            features['is_cruise_day'].iloc[0] * 3 +
            features['tourist_season'].iloc[0]
        )
        
        # æ¬ æã—ã¦ã„ã‚‹ç‰¹å¾´é‡ã‚’0ã§åŸ‹ã‚ã‚‹
        for col in self.feature_names:
            if col not in features.columns:
                features[col] = 0
        
        # ç‰¹å¾´é‡ã®é †åºã‚’åˆã‚ã›ã‚‹
        features = features[self.feature_names]
        
        return features
    
    def _apply_ishigaki_adjustments(self, base_prediction: float, guest: Dict, 
                                  environmental_data: Dict) -> float:
        """çŸ³å£å³¶ç‰¹æœ‰ã®èª¿æ•´ã‚’é©ç”¨"""
        
        adjusted = base_prediction
        
        # å°é¢¨è­¦å ±ãƒ¬ãƒ™ãƒ«èª¿æ•´
        if environmental_data.get('typhoon_risk', 0) > 0.3:
            adjusted *= 2.0  # å°é¢¨æ™‚ã¯å¤§å¹…é…å»¶
        
        # è¦³å…‰ã‚·ãƒ¼ã‚ºãƒ³èª¿æ•´
        month = environmental_data.get('month', 1)
        if month in [7, 8]:  # å¤ä¼‘ã¿ãƒ”ãƒ¼ã‚¯
            adjusted *= 1.3
        elif month in [1, 2, 3]:  # å†¬ã®è¦³å…‰ãƒ”ãƒ¼ã‚¯
            adjusted *= 1.2
        
        # ã‚¯ãƒ«ãƒ¼ã‚ºèˆ¹å¯„æ¸¯æ—¥èª¿æ•´
        if environmental_data.get('is_cruise_day', False):
            adjusted *= 1.5
        
        # æ½®ä½ã«ã‚ˆã‚‹æµ·å²¸é“è·¯å½±éŸ¿
        tide_level = environmental_data.get('tide_level', 150)
        if tide_level > 200:  # ç•°å¸¸é«˜æ½®ä½
            adjusted *= 1.2
        
        return adjusted
    
    def _identify_ishigaki_factors(self, guest: Dict, environmental_data: Dict) -> List[str]:
        """çŸ³å£å³¶ç‰¹æœ‰ã®å½±éŸ¿è¦å› ã‚’ç‰¹å®š"""
        factors = []
        
        month = environmental_data.get('month', 1)
        
        if month in [7, 8]:
            factors.append("å¤ä¼‘ã¿è¦³å…‰ãƒ”ãƒ¼ã‚¯æœŸ")
        
        if environmental_data.get('typhoon_risk', 0) > 0.1:
            factors.append("å°é¢¨ã‚·ãƒ¼ã‚ºãƒ³")
        
        if environmental_data.get('is_cruise_day', False):
            factors.append("ã‚¯ãƒ«ãƒ¼ã‚ºèˆ¹å¯„æ¸¯æ—¥")
        
        if environmental_data.get('tide_level', 150) > 180:
            factors.append("é«˜æ½®ä½ã«ã‚ˆã‚‹å½±éŸ¿")
        
        return factors
    
    def _get_ishigaki_environmental_data(self, date: str) -> Dict:
        """çŸ³å£å³¶ã®ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            date_obj = datetime.strptime(date, '%Y-%m-%d')
        except:
            date_obj = datetime.now()
        
        month = date_obj.month
        day = date_obj.day
        
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å¤–éƒ¨APIã‹ã‚‰å–å¾—
        return {
            'month': month,
            'typhoon_risk': 0.2 if month in self.ishigaki_features['typhoon_months'] else 0.0,
            'weather': 'rainy' if month in [6, 9, 10] else 'sunny',
            'tide_level': 150 + np.random.normal(0, 30),  # å®Ÿéš›ã¯æ½®ä½APIã‹ã‚‰å–å¾—
            'is_cruise_day': day in self.ishigaki_features['cruise_ship_days'],
            'wind_speed': np.random.uniform(2, 8),  # å®Ÿéš›ã¯æ°—è±¡APIã‹ã‚‰å–å¾—
            'temperature': 25 + (month - 6) * 2 if month <= 8 else 30 - (month - 8) * 2
        }
    
    def _calculate_ishigaki_confidence(self, guest_count: int, environmental_data: Dict) -> float:
        """çŸ³å£å³¶ç‰¹æœ‰ã®ä¿¡é ¼åº¦è¨ˆç®—"""
        base_confidence = 85
        
        # ãƒ‡ãƒ¼ã‚¿è“„ç©ã«ã‚ˆã‚‹ä¿¡é ¼åº¦å‘ä¸Š
        if self.last_trained:
            days_since_training = (datetime.now() - datetime.fromisoformat(self.last_trained)).days
            if days_since_training < 30:
                base_confidence += 5
        
        # å°é¢¨ãªã©ã®äºˆæ¸¬å›°é›£ãªçŠ¶æ³ã§ã¯ä¿¡é ¼åº¦ä½ä¸‹
        if environmental_data.get('typhoon_risk', 0) > 0.3:
            base_confidence -= 15
        
        # ã‚²ã‚¹ãƒˆæ•°ã«ã‚ˆã‚‹èª¿æ•´
        if guest_count <= 8:
            base_confidence += 5  # å°‘æ•°ç²¾é‹­ã§äºˆæ¸¬ã—ã‚„ã™ã„
        elif guest_count >= 20:
            base_confidence -= 5  # å¤§äººæ•°ã§å¤‰å‹•è¦å› å¢—åŠ 
        
        return min(95, max(60, base_confidence))
    
    def _generate_ishigaki_recommendations(self, date: str, activity_type: str,
                                         expected_delays: List[Dict], 
                                         environmental_data: Dict) -> List[str]:
        """çŸ³å£å³¶ç‰¹æœ‰ã®æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        month = environmental_data.get('month', 1)
        
        # å­£ç¯€åˆ¥æ¨å¥¨
        if month in [7, 8]:
            recommendations.append("ğŸŒ å¤ã®è¦³å…‰ãƒ”ãƒ¼ã‚¯æœŸã§ã™ã€‚é€šå¸¸ã‚ˆã‚Š30åˆ†æ—©ã‚ã®å‡ºç™ºã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        elif month in [1, 2, 3]:
            recommendations.append("â„ï¸ å†¬ã®è¦³å…‰ã‚·ãƒ¼ã‚ºãƒ³ã§ã™ã€‚åŒ—é¢¨ãŒå¼·ã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
        elif month in self.ishigaki_features['typhoon_months']:
            recommendations.append("ğŸŒ€ å°é¢¨ã‚·ãƒ¼ã‚ºãƒ³ã§ã™ã€‚æœ€æ–°ã®æ°—è±¡æƒ…å ±ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        
        # æ´»å‹•ã‚¿ã‚¤ãƒ—åˆ¥æ¨å¥¨
        if activity_type == 'snorkeling':
            tide_level = environmental_data.get('tide_level', 150)
            if tide_level > 170:
                recommendations.append("ğŸŒŠ é«˜æ½®ä½ã®ãŸã‚ã€ã‚·ãƒ¥ãƒãƒ¼ã‚±ãƒªãƒ³ã‚°ã«æœ€é©ãªæ¡ä»¶ã§ã™ã€‚")
            elif tide_level < 120:
                recommendations.append("ğŸ–ï¸ å¹²æ½®æ™‚ã®ãŸã‚ã€æµ…ç€¬ã§ã®è¦³å¯ŸãŒã—ã‚„ã™ããªã‚Šã¾ã™ã€‚")
        
        elif activity_type == 'diving':
            recommendations.append("ğŸ¤¿ çŸ³å£å³¶ã®é€æ˜åº¦ã¯ä¸–ç•Œãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã€‚å­˜åˆ†ã«ãŠæ¥½ã—ã¿ãã ã•ã„ã€‚")
        
        elif activity_type in ['kayak', 'sup']:
            wind_speed = environmental_data.get('wind_speed', 3)
            if wind_speed > 5:
                recommendations.append("ğŸ’¨ é¢¨ãŒå¼·ã‚ã§ã™ã€‚åˆå¿ƒè€…ã®æ–¹ã¯æ³¨æ„ã—ã¦ãã ã•ã„ã€‚")
        
        # äº¤é€šé–¢é€£æ¨å¥¨
        if environmental_data.get('is_cruise_day', False):
            recommendations.append("ğŸš¢ ã‚¯ãƒ«ãƒ¼ã‚ºèˆ¹å¯„æ¸¯æ—¥ã®ãŸã‚ã€å¸‚è¡—åœ°ã®äº¤é€šæ¸‹æ»ã«ã”æ³¨æ„ãã ã•ã„ã€‚")
        
        # é…å»¶äºˆæ¸¬ã«åŸºã¥ãæ¨å¥¨
        max_delay = max([d['predicted_delay'] for d in expected_delays], default=0)
        if max_delay > 15:
            recommendations.append(f"â° æœ€å¤§{max_delay}åˆ†ã®é…å»¶ãŒäºˆæƒ³ã•ã‚Œã¾ã™ã€‚ä½™è£•ã‚’æŒã£ãŸè¨ˆç”»ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        elif max_delay < 5:
            recommendations.append("âœ… ã‚¹ãƒ ãƒ¼ã‚ºãªé€è¿ãŒäºˆæƒ³ã•ã‚Œã¾ã™ã€‚äºˆå®šé€šã‚Šã®é€²è¡ŒãŒæœŸå¾…ã§ãã¾ã™ã€‚")
        
        # çŸ³å£å³¶ç‰¹æœ‰ã®æ¨å¥¨
        recommendations.append("ğŸï¸ çŸ³å£å³¶ã®ç¾ã—ã„è‡ªç„¶ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ã€‚ç§»å‹•ä¸­ã‚‚çµ¶æ™¯ãƒã‚¤ãƒ³ãƒˆã‚’ã”æ¡ˆå†…ã—ã¾ã™ã€‚")
        
        if month in [11, 12, 1, 2]:
            recommendations.append("ğŸ‹ ã“ã®æ™‚æœŸã¯ã‚¶ãƒˆã‚¦ã‚¯ã‚¸ãƒ©ã®å›éŠã‚·ãƒ¼ã‚ºãƒ³ã§ã™ã€‚")
        
        return recommendations
    
    def _generate_weather_alerts(self, environmental_data: Dict) -> List[str]:
        """å¤©å€™ã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆ"""
        alerts = []
        
        typhoon_risk = environmental_data.get('typhoon_risk', 0)
        if typhoon_risk > 0.5:
            alerts.append("ğŸš¨ å°é¢¨è­¦å ±: å¼·ã„å°é¢¨ã®å½±éŸ¿ãŒäºˆæƒ³ã•ã‚Œã¾ã™")
        elif typhoon_risk > 0.3:
            alerts.append("âš ï¸ å°é¢¨æ³¨æ„: å°é¢¨ã®å½±éŸ¿ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        wind_speed = environmental_data.get('wind_speed', 3)
        if wind_speed > 8:
            alerts.append("ğŸ’¨ å¼·é¢¨æ³¨æ„: æµ·ä¸Šæ´»å‹•ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        weather = environmental_data.get('weather', 'sunny')
        if weather == 'rainy':
            alerts.append("â˜” é›¨å¤©äºˆå ±: é“è·¯çŠ¶æ³ã®æ‚ªåŒ–ã«ã”æ³¨æ„ãã ã•ã„")
        
        return alerts
    
    def _generate_tide_advisory(self, environmental_data: Dict) -> List[str]:
        """æ½®ä½ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆ"""
        advisory = []
        
        tide_level = environmental_data.get('tide_level', 150)
        
        if tide_level > 200:
            advisory.append("ğŸŒŠ å¤§æ½®: éå¸¸ã«é«˜ã„æ½®ä½ã§ã™ã€‚æµ·å²¸é“è·¯ã®é€šè¡Œã«ã”æ³¨æ„ãã ã•ã„ã€‚")
        elif tide_level > 170:
            advisory.append("ğŸŒŠ é«˜æ½®: æµ·æ´‹ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã«é©ã—ãŸæ½®ä½ã§ã™ã€‚")
        elif tide_level < 100:
            advisory.append("ğŸ–ï¸ å¹²æ½®: æµ…ç€¬ãŒåºƒãŒã‚Šã€ãƒ“ãƒ¼ãƒã‚³ãƒ¼ãƒŸãƒ³ã‚°ã«æœ€é©ã§ã™ã€‚")
        elif tide_level < 120:
            advisory.append("ğŸ–ï¸ ä½æ½®: æ™®æ®µè¦‹ãˆãªã„å²©å ´ã‚„ç”Ÿç‰©è¦³å¯ŸãŒã§ãã¾ã™ã€‚")
        
        return advisory
    
    def _generate_model_notes(self, feature_importance: pd.DataFrame) -> List[str]:
        """ãƒ¢ãƒ‡ãƒ«ç‰¹æ€§ã«é–¢ã™ã‚‹æ³¨é‡ˆ"""
        notes = []
        
        top_features = feature_importance.head(5)['feature'].tolist()
        
        notes.append(f"ğŸ” æœ€ã‚‚å½±éŸ¿ã™ã‚‹è¦å› : {', '.join(top_features[:3])}")
        
        if 'tourist_season' in top_features:
            notes.append("ğŸ“ˆ è¦³å…‰ã‚·ãƒ¼ã‚ºãƒ³ãŒé…å»¶ã«å¤§ããå½±éŸ¿ã—ã¦ã„ã¾ã™")
        
        if 'tide_level' in top_features:
            notes.append("ğŸŒŠ æ½®ä½ãŒçŸ³å£å³¶ã®äº¤é€šã«é‡è¦ãªå½±éŸ¿ã‚’ä¸ãˆã¦ã„ã¾ã™")
        
        if 'traffic_congestion_score' in top_features:
            notes.append("ğŸš— äº¤é€šæ¸‹æ»äºˆæ¸¬ã‚¹ã‚³ã‚¢ãŒé«˜ã„ç²¾åº¦ã‚’ç¤ºã—ã¦ã„ã¾ã™")
        
        return notes
    
    def load_model(self):
        """ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            for model_name in self.models.keys():
                model_path = os.path.join(self.model_dir, f'ishigaki_{model_name}_model.pkl')
                if os.path.exists(model_path):
                    self.models[model_name] = joblib.load(model_path)
                    print(f"çŸ³å£å³¶{model_name}ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
            meta_path = os.path.join(self.model_dir, 'ishigaki_model_metadata.json')
            if os.path.exists(meta_path):
                with open(meta_path, 'r') as f:
                    metadata = json.load(f)
                    self.feature_names = metadata.get('feature_names', [])
                    self.last_trained = metadata.get('last_trained')
                    self.ensemble_weights = metadata.get('ensemble_weights', self.ensemble_weights)
        except Exception as e:
            print(f"çŸ³å£å³¶ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _save_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜"""
        for model_name, model in self.models.items():
            if model is not None:
                model_path = os.path.join(self.model_dir, f'ishigaki_{model_name}_model.pkl')
                joblib.dump(model, model_path)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        metadata = {
            'location': 'çŸ³å£å³¶',
            'feature_names': self.feature_names,
            'last_trained': datetime.now().isoformat(),
            'ensemble_weights': self.ensemble_weights,
            'ishigaki_version': '1.0'
        }
        
        meta_path = os.path.join(self.model_dir, 'ishigaki_model_metadata.json')
        with open(meta_path, 'w') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        self.last_trained = metadata['last_trained']